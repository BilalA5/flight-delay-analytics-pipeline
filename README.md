# Flight Delay Analytics Pipeline

A production-ready data engineering pipeline for analyzing US flight delay data using modern data stack: **Docker**, **PostgreSQL**, **Apache Airflow**, and **dbt**.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingest    â”‚â”€â”€â”€â”€â–¶â”‚  Transform   â”‚â”€â”€â”€â”€â–¶â”‚  Aggregate  â”‚â”€â”€â”€â”€â–¶â”‚  Analytics   â”‚
â”‚  (Python)   â”‚     â”‚    (dbt)     â”‚     â”‚   (dbt)     â”‚     â”‚  Dashboard   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                     â”‚
       â–¼                    â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL Database                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   raw   â”‚â”€â”€â”€â–¶â”‚ staging  â”‚â”€â”€â”€â–¶â”‚    analytics      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Airflow (DAG)   â”‚
              â”‚   Orchestration  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow
1. **Ingest**: Raw flight data loaded into `raw.flights` table
2. **Transform**: Data cleaned and deduplicated via dbt staging models
3. **Aggregate**: Analytics tables created for KPIs and reporting
4. **Orchestration**: Airflow DAG manages the entire pipeline

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd flight-delay-analytics-pipeline
```

2. **Start the services**
```bash
docker-compose up -d
```

3. **Access Airflow UI**
- URL: http://localhost:8080
- Username: `admin`
- Password: `admin`

4. **Trigger the pipeline**
- Navigate to DAGs
- Enable `flight_delay_pipeline`
- Trigger manually or wait for scheduled run (daily at 2 AM)

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ dags/                          # Airflow DAGs
â”‚   â””â”€â”€ flight_delay_pipeline.py  # Main ETL orchestration
â”œâ”€â”€ pipeline/                      # Python ETL modules
â”‚   â”œâ”€â”€ ingest.py                 # Data ingestion
â”‚   â”œâ”€â”€ transform.py              # Data transformation
â”‚   â””â”€â”€ aggregate.py              # Data aggregation
â”œâ”€â”€ dbt_project/                  # dbt transformations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/              # Staging models
â”‚   â”‚   â””â”€â”€ analytics/            # Analytics models
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ sql/                          # SQL scripts
â”‚   â”œâ”€â”€ init.sql                  # Database initialization
â”‚   â””â”€â”€ kpi_queries.sql           # KPI queries
â”œâ”€â”€ docker-compose.yml            # Service orchestration
â”œâ”€â”€ Dockerfile                    # Application container
â””â”€â”€ requirements.txt              # Python dependencies
```

## ğŸ”§ Configuration

### Environment Variables
Copy `.env.example` to `.env` and adjust as needed:
```bash
cp .env.example .env
```

### Database Schemas
- **raw**: Ingested raw data
- **staging**: Cleaned and validated data
- **analytics**: Aggregated metrics and KPIs

## ğŸ“Š Analytics Tables

### `analytics.daily_airline_stats`
Daily performance metrics by airline:
- Total flights
- Cancellation rate
- Average delays
- On-time percentage

### `analytics.route_performance`
Route-level analysis:
- Flight volume
- Average delays
- On-time performance

## ğŸ§ª Running dbt Models

```bash
# Enter the dbt container
docker-compose exec airflow-webserver bash

# Navigate to dbt project
cd /opt/airflow/dbt_project

# Run models
dbt run

# Run tests
dbt test
```

## ğŸ“ˆ Monitoring

- **Airflow UI**: http://localhost:8080
- **Postgres**: localhost:5432
  - Database: `airflow`
  - User: `airflow`
  - Password: `airflow`

## ğŸ› ï¸ Development

### Adding New Models
1. Create SQL file in `dbt_project/models/`
2. Define in `schema.yml`
3. Run `dbt run` to materialize

### Modifying Pipeline
1. Edit Python modules in `pipeline/`
2. Update DAG in `dags/flight_delay_pipeline.py`
3. Rebuild container: `docker-compose up -d --build`

## ğŸ“ License

See LICENSE file for details.
